{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEwo3o7iHc+Kn3iO4Yjf5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beryaelio/chatbot/blob/main/chatbot_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple chatbot using the NLTK and sklearn python libraries.\n",
        "The data is from a Wikipedia page about Artificial Neural Network:\n",
        "https://en.wikipedia.org/wiki/Artificial_neural_network  \n"
      ],
      "metadata": {
        "id": "UFLcy7trA-X5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Kyhb-q80TCO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "f = open('/content/drive/MyDrive/chatbot/artificial_neural_network_wiki_data.txt', 'r', errors = 'ignore')\n",
        "raw_data = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSIzojpg9i0r",
        "outputId": "0aea5a61-3109-4b00-a165-9e808fb40b88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After I've opened the data, I'll tokenize it."
      ],
      "metadata": {
        "id": "nNXflf6Fb_Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = raw_data.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "sentence_tokens = nltk.sent_tokenize(raw_data)\n",
        "word_tokens = nltk.word_tokenize(raw_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VtyJvlH-c01",
        "outputId": "1bd7eeba-c21d-4923-d157-91596225b312"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After tokenizing I'll lemmetize the tokens."
      ],
      "metadata": {
        "id": "8SVaC9pNcL4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punt_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punt_dict)))"
      ],
      "metadata": {
        "id": "robvNTPS_RHV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I make a function for the greeting as well. So the bot will be polite:)"
      ],
      "metadata": {
        "id": "G1nyJD-LczQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_input = ('hello', 'hi', 'how are you?')\n",
        "greet_response = ('hi', 'hey')\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_input:\n",
        "      return random.choice(greet_response)"
      ],
      "metadata": {
        "id": "cjWMFdgqARZo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now in here is where the magic happens. Based on the user's input, using the feature extraction method: Term Frequency-Inverse Document Frequency Vectorizer and the cosine similarity metric, the bot will find text in the data that most likely the user queries about. Based on similarity between the user input and the data, the bot will either return no similarity found therefore another query is needed or a subtext that most probably matches the user input."
      ],
      "metadata": {
        "id": "O39uOBarc8n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo_response = ''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
        "  Tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "  vals = cosine_similarity(Tfidf[-1], Tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  reqTfidf = flat[-2]\n",
        "  if (reqTfidf == 0):\n",
        "    robo_response = robo_response + \"Sorry I can't understand you please try again\"\n",
        "    return robo_response\n",
        "  else:\n",
        "    robo_response = robo_response + sentence_tokens[idx]\n",
        "    return robo_response"
      ],
      "metadata": {
        "id": "hIjitdrkA2J5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This the last part, which is the functionality of the bot. Based on the user's input, the code will determine whether to return a greeting, a response or exit the run."
      ],
      "metadata": {
        "id": "3I2gmFYveLsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print('Hello, start typing your text after greeting to talk to me. For ending convo type bye!')\n",
        "while(flag == True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response != 'bye!'):\n",
        "    if(user_response == 'Thanks' or user_response == 'Thank you'):\n",
        "      flag = False\n",
        "      print('Happy to help!')\n",
        "    else:\n",
        "      if(greet(user_response) != None):\n",
        "        print('Bot: '+ greet(user_response))\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)\n",
        "        word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print('Bot: ', end = '')\n",
        "        print(response(user_response))\n",
        "        sentence_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag = False\n",
        "    print('Bot: Goodbye!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFIQAEhaDBPl",
        "outputId": "4fc53674-b1b0-49e1-ad1a-b35eea61e067"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, start typing your text after greeting to talk to me. For ending convo type bye!\n",
            "hi\n",
            "Bot: hey\n",
            "I want to know about neural networks\n",
            "Bot: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artificial neural networks (anns, also shortened to neural networks (nns) or neural nets) are a branch of machine learning models that are built using principles of neuronal organization discovered by connectionism in the biological neural networks constituting animal brains.\n",
            "are there models?\n",
            "Bot: the first network is a generative model that models a probability distribution over output patterns.\n",
            "what else can you tell me about artificial functions \n",
            "Bot: artificial neurons\n",
            "anns are composed of artificial neurons which are conceptually derived from biological neurons.\n",
            "ok thank you, bye!\n",
            "Bot: Sorry I can't understand you please try again\n",
            "bye!\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a very simple chatbot, the quality of the answers depends on the quality of the data and any upgrades that can be done to the code.\n",
        ""
      ],
      "metadata": {
        "id": "uagG4L2chsvd"
      }
    }
  ]
}